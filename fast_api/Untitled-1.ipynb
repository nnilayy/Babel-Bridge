{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans\n",
    "from translator import translate\n",
    "text=translate(\"HI how are you\", \"ko\")\n",
    "# text\n",
    "# translator = googletrans.Translator().translate(\"नमस्ते\", dest=\"ko\")\n",
    "# translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "translator=GoogleTranslator(source='english', target='hid')\n",
    "text=translator.translate(\"keep it up, you are black ass pussy\") \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "'bengali': 'bn', \n",
    "'chinese (simplified)': 'zh-CN', \n",
    "'chinese (traditional)': 'zh-TW',  \n",
    "'english': 'en', \n",
    "'french': 'fr',\n",
    "'german': 'de', \n",
    "'hindi': 'hi',\n",
    "'japanese': 'ja',\n",
    "'korean': 'ko', \n",
    "'marathi': 'mr',\n",
    "'punjabi': 'pa', \n",
    "'russian': 'ru',\n",
    "'spanish': 'es',\n",
    "'tamil': 'ta', \n",
    "'telugu': 'te', \n",
    "'urdu': 'ur',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "translator.translate(\"Der Himmel ist blau und ich mag Bananen\", dest='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google_trans_new\n",
    "from google_trans_new import google_translator  \n",
    "  \n",
    "translator = google_translator()  \n",
    "translate_text = translator.translate('Hola mundo!', lang_src='est', lang_tgt='en')  \n",
    "print(translate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -U deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import argparse\n",
    "\n",
    "def audio_2_text_hindi(wav_file_path):\n",
    "    # Load pretrained model\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
    "\n",
    "    # Load audio and resample to 16,000Hz\n",
    "    audio_input, original_sample_rate = sf.read(wav_file_path)\n",
    "    resampler = torchaudio.transforms.Resample(original_sample_rate, 16000)\n",
    "    audio_input = resampler(torch.tensor(audio_input)).numpy()\n",
    "\n",
    "    # Set the segment duration (e.g., 2 seconds)\n",
    "    segment_duration = 2  # Adjust as needed\n",
    "\n",
    "    # Calculate the number of segments\n",
    "    num_samples = len(audio_input)\n",
    "    num_samples_per_segment = int(segment_duration * 16000)\n",
    "    num_segments = num_samples // num_samples_per_segment\n",
    "\n",
    "    # Transcribe each segment\n",
    "    transcriptions = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * num_samples_per_segment\n",
    "        end_sample = (i + 1) * num_samples_per_segment\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = audio_input[start_sample:end_sample]\n",
    "\n",
    "        # Pad input values and return pt tensor\n",
    "        input_values = processor(segment, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "\n",
    "        # INFERENCE\n",
    "        # Retrieve logits & take argmax\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Transcribe the segment\n",
    "        transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        transcriptions.append(transcription)\n",
    "\n",
    "    # Combine the transcriptions from all segments\n",
    "    final_transcription = \" \".join(transcriptions)\n",
    "    return final_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def validate_wav_format(file_path):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(file_path, format=\"wav\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error validating WAV format:\", str(e))\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_wav_format(r\"C:\\Users\\Nilay Kumar\\Desktop\\SIH\\fast_api\\recorded.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -U pydub\n",
    "!python -m pip install -U ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'recorded.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nilay Kumar\\Desktop\\SIH\\fast_api\\Untitled-1.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nilay%20Kumar/Desktop/SIH/fast_api/Untitled-1.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m audio_preprocessing(\u001b[39m\"\u001b[39;49m\u001b[39mrecorded.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Nilay Kumar\\Desktop\\SIH\\fast_api\\Untitled-1.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nilay%20Kumar/Desktop/SIH/fast_api/Untitled-1.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m audio \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39mfrom_file(audio_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nilay%20Kumar/Desktop/SIH/fast_api/Untitled-1.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m AudioSegment\u001b[39m.\u001b[39mconverter\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mNilay Kumar\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mSIH\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfast_api\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mffmpeg.exe\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nilay%20Kumar/Desktop/SIH/fast_api/Untitled-1.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m os\u001b[39m.\u001b[39;49mremove(audio_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nilay%20Kumar/Desktop/SIH/fast_api/Untitled-1.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m audio\u001b[39m.\u001b[39mexport(os\u001b[39m.\u001b[39mgetcwd()\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maudio.wav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'recorded.wav'"
     ]
    }
   ],
   "source": [
    "audio_preprocessing(\"recorded.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "def audio_preprocessing(audio_path):\n",
    "  audio = AudioSegment.from_file(audio_path)\n",
    "  AudioSegment.converter=r\"C:\\Users\\Nilay Kumar\\Desktop\\SIH\\fast_api\\ffmpeg.exe\"\n",
    "  os.remove(audio_path)\n",
    "  audio.export(os.getcwd()+\"/\"+\"audio.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
